1) Make sure SECTIONS actually has content

Open src/league-content.(ts|js). If you still see text: "" placeholders, fill them with the real bylaws/rules/board/etc. If that file is empty, retrieval will always feed an empty CONTEXT and the model won’t answer.

2) Add smart guardrails + early answers in the function

If the user asks what model they’re speaking to, answer without calling OpenAI.

If retrieval returns no context, show a helpful guardrail message (not a generic error).

Keep your robust extractor.

Drop-in patch (handler.js):

// netlify/functions/src/handler.js
import OpenAI from "openai";
import { baseSystemPrompt } from "./prompt.js";
import { getRelevantSections } from "./retrieval.js";

export const CURRENT_OPENAI_MODEL = "gpt-5-nano";
const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });

const DEBUG = process.env.DEBUG_AI === "1";

function extractText(r) {
  if (typeof r?.output_text === "string" && r.output_text.trim()) return r.output_text.trim();
  if (Array.isArray(r?.output)) {
    const parts = [];
    for (const item of r.output) {
      if (item?.type === "output_text" && item.text) parts.push(item.text);
      if (item?.type === "message" && Array.isArray(item.content)) {
        for (const c of item.content) {
          if ((c.type === "text" || c.type === "output_text") && c.text) parts.push(c.text);
        }
      }
    }
    const joined = parts.join("").trim();
    if (joined) return joined;
  }
  const choiceText = r?.choices?.[0]?.message?.content;
  if (typeof choiceText === "string" && choiceText.trim()) return choiceText.trim();
  return "";
}

function isModelQuestion(msg) {
  return /\b(what|which)\b.*\bmodel\b|\bgpt\b.*\b(am|is)\b/i.test(msg);
}

export async function getChatbotResponse(userMessage) {
  // 0) Answer model questions locally
  if (isModelQuestion(userMessage)) {
    return `You’re chatting with ${CURRENT_OPENAI_MODEL}.`;
  }

  // 1) Retrieve only relevant sections
  const context = getRelevantSections(userMessage, { maxSections: 3, maxChars: 2500 });
  if (DEBUG) console.log("CTX len:", context?.length, "Preview:", (context || "").slice(0, 200));

  // 2) If retrieval found nothing, follow the guardrail immediately
  if (!context || !context.trim()) {
    return "Aloha — I don’t have that in my documents yet. If unsure or a rule isn’t specified, please ask a clarifying question or contact the Board via the website.";
  }

  // 3) Ask the model with system instructions + context
  try {
    const r = await openai.responses.create({
      model: CURRENT_OPENAI_MODEL,
      instructions: baseSystemPrompt.trim(),
      input: `Question:
${userMessage}

CONTEXT (relevant excerpts only):
${context}`,
      max_output_tokens: 800
    });

    const answer = extractText(r).trim();
    return answer || "Aloha — I couldn’t find that in the provided documents. If unsure or a rule isn’t specified, please contact the Board.";
  } catch (err) {
    console.error("OpenAI API error:", err.status ?? err.response?.status, err.message, err.response?.data);
    throw err;
  }
}

3) Make retrieval actually “find” things (HR/“home run” example)

Add tags/synonyms so questions like “home runs” match your Rules section even if wording differs (“HR limit”).

Patch src/retrieval.(ts|js) (key differences: synonym mapping + tag boosts + a fallback for HR):

import { SECTIONS } from "./league-content.js";

const SYNONYMS = {
  "home run": ["home runs", "homer", "hr", "dinger", "over the fence"],
  "courtesy runner": ["pinch runner", "courtesy"],
  "tiebreaker": ["international tiebreaker", "extra innings", "one-pitch"],
};

function expandQuery(q) {
  const base = q.toLowerCase();
  const extras = [];
  for (const [k, vals] of Object.entries(SYNONYMS)) {
    if (base.includes(k) || vals.some(v => base.includes(v))) {
      extras.push(k, ...vals);
    }
  }
  return Array.from(new Set([base, ...extras]));
}

export function getRelevantSections(query, options = {}) {
  const { maxSections = 3, maxChars = 2500 } = options;
  const terms = expandQuery(query);

  const scored = [];
  for (const s of SECTIONS) {
    const hay = (s.title + "\n" + (s.text || "") + "\n" + (s.tags || []).join(" ")).toLowerCase();
    let score = 0;
    for (const t of terms) if (hay.includes(t)) score += 2;     // term match
    for (const tag of (s.tags || [])) for (const t of terms) if (tag.includes(t)) score += 1; // tag boost
    if (hay.includes(query.toLowerCase())) score += 3;         // exact phrase boost
    if (score > 0) scored.push({ s, score });
  }

  // Fallback routing: if user asks about home runs, force include Rules section
  if (!scored.length && /\bhome\s*runs?\b|\bhr\b/i.test(query)) {
    const rules = SECTIONS.find(sec => sec.id === "rules" || /gameplay rules/i.test(sec.title));
    if (rules) scored.push({ s: rules, score: 1 });
  }

  const top = scored.sort((a, b) => b.score - a.score).slice(0, maxSections);
  let out = top.map(({ s }) => `### ${s.title}\n${s.text}`).join("\n\n");
  if (out.length > maxChars) out = out.slice(0, maxChars) + "\n…";
  return out;
}


Important: In league-content, give each section helpful tags, e.g. for Rules:

{
  id: "rules",
  title: "Gameplay Rules",
  tags: ["home run", "hr limit", "courtesy runner", "time limit", "international tiebreaker"],
  text: `...include the actual text e.g., "Home run limits: C: 1, D: 0, E: 0" ...`
}